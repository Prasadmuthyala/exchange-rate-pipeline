USE DATABASE MYDB

CREATE OR REPLACE TABLE MYDB.PUBLIC.EXCHANGERATE(
ID INTEGER,
currency STRING,
rate FLOAT,
date DATE,
last_update_date DATE,
next_update_date DATE
)

CREATE OR REPLACE TABLE MYDB.TARGETTABLES.NEWEXCHANGERATE(
ID INTEGER,
currency STRING,
rate FLOAT,
date DATE,
last_update_date DATE,
next_update_date DATE
)

CREATE STORAGE INTEGRATION IF NOT EXISTS EXCHANGERATEINTEGRATION
    TYPE = EXTERNAL_STAGE
    STORAGE_PROVIDER='S3'
    ENABLED = TRUE
    STORAGE_AWS_ROLE_ARN='arn:aws:iam::438465132279:role/snowflake-access-role'
    STORAGE_ALLOWED_LOCATIONS=('s3://exchangerateapi/intermediateTransformedData/','s3://exchangerateapi/finaltransformeddata/')

;
DESC INTEGRATION EXCHANGERATEINTEGRATION //need to add STORAGE_AWS_EXTERNAL_ID to Role(trust policy)

-- Create a file format for Parquet files
CREATE OR REPLACE FILE FORMAT mydb.file_formats.my_parquet_format
  TYPE = 'PARQUET'
  COMPRESSION = 'SNAPPY'

CREATE OR REPLACE STAGE MYDB.EXTERNAL_STAGES.EXCHANGERATESTAGE
URL='s3://exchangerateapi/intermediateTransformedData/'
STORAGE_INTEGRATION=EXCHANGERATEINTEGRATION
FILE_FORMAT = mydb.file_formats.my_parquet_format

DESC STAGE MYDB.EXTERNAL_STAGES.EXCHANGERATESTAGE

-- Create the pipe for automatic ingestion
CREATE OR REPLACE PIPE MYDB.PIPES.EXCHANGERATEPIPE
  AUTO_INGEST = TRUE
AS
  COPY INTO MYDB.PUBLIC.EXCHANGERATE
  FROM (SELECT
        $1:ID::INTEGER AS ID,
        $1:currency::STRING AS currency,
        $1:rate::FLOAT AS rate,
        TO_DATE($1:date::STRING, 'DD-MM-YYYY') AS date,
        TO_DATE($1:last_update_date::STRING, 'DD-MM-YYYY') AS last_update_date,
        TO_DATE($1:next_update_date::STRING, 'DD-MM-YYYY') AS next_update_date
    FROM @MYDB.EXTERNAL_STAGES.EXCHANGERATESTAGE)
  ON_ERROR = 'CONTINUE'
  
  ;

DESC PIPE MYDB.PIPES.EXCHANGERATEPIPE;
select * from MYDB.PUBLIC.EXCHANGERATE

-- Create a stream to track changes on a target table (e.g., 'my_table')
CREATE OR REPLACE STREAM MYDB.mystreams.EXCHANGERATESTREAM
  ON TABLE MYDB.PUBLIC.EXCHANGERATE
  SHOW_INITIAL_ROWS = TRUE; -- To capture the initial state of the table as well

SELECT * FROM  MYDB.mystreams.EXCHANGERATESTREAM;


CREATE OR REPLACE TASK MYDB.MYTASKS.EXCHANGERATETASK
WAREHOUSE = 'DUMMYWAREHOUSE'
SCHEDULE = 'USING CRON * * * * * America/Los_Angeles'
WHEN SYSTEM$STREAM_HAS_DATA('MYDB.mystreams.EXCHANGERATESTREAM')
AS
MERGE INTO MYDB.TARGETTABLES.NEWEXCHANGERATE T
USING (
    SELECT 
        SS.ID, 
        SS.CURRENCY, 
        SS.RATE,
        SS.DATE,
        SS.LAST_UPDATE_DATE,
        SS.NEXT_UPDATE_DATE,
        SS.METADATA$ACTION, 
        SS.METADATA$ISUPDATE
    FROM MYDB.mystreams.EXCHANGERATESTREAM SS
) SS
ON T.ID = SS.ID
WHEN MATCHED AND SS.METADATA$ACTION = 'UPDATE' AND SS.METADATA$ISUPDATE = TRUE THEN
    UPDATE SET T.ID=SS.ID, 
        T.CURRENCY=SS.CURRENCY, 
        T.RATE=SS.RATE,
        T.DATE=SS.DATE,
        T.LAST_UPDATE_DATE=SS.LAST_UPDATE_DATE,
        T.NEXT_UPDATE_DATE=SS.NEXT_UPDATE_DATE
WHEN NOT MATCHED AND SS.METADATA$ACTION = 'INSERT' THEN
    INSERT (ID,CURRENCY,RATE,DATE,LAST_UPDATE_DATE,NEXT_UPDATE_DATE)
    VALUES (SS.ID, SS.CURRENCY, SS.RATE,SS.DATE,SS.LAST_UPDATE_DATE,SS.NEXT_UPDATE_DATE)
WHEN MATCHED AND SS.METADATA$ACTION = 'DELETE' AND SS.METADATA$ISUPDATE = FALSE THEN
    DELETE;



-- Resume the task (if necessary)
ALTER TASK MYDB.MYTASKS.EXCHANGERATETASK SUSPEND;
ALTER TASK MYDB.MYTASKS.EXCHANGERATETASK RESUME;
select * from MYDB.TARGETTABLES.NEWEXCHANGERATE order by ID 
Select * from MYDB.PUBLIC.EXCHANGERATE
-- Disable result caching for the current session
ALTER SESSION SET USE_CACHED_RESULT = FALSE;

-- Insert a test row
UPDATE MYDB.PUBLIC.EXCHANGERATE
SET RATE = 1.5
WHERE ID = 1001;